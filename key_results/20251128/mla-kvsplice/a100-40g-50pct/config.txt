
#
# General Configuration
#

#
# Hyperparameter Auto-Detection - See docs/hyperparameter-auto-detection.md
#
CONFIG_HYPER_PARAM_AUTO=y
# CONFIG_HYPER_PARAM_MANUAL is not set
CONFIG_NUM_EPOCHS=10
CONFIG_LEARNING_RATE="6e-4"
CONFIG_NUM_WORKERS=16
CONFIG_DEVICE="cuda"
CONFIG_PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"
CONFIG_TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=y
CONFIG_DATA_DIR="./gpt2/data"
CONFIG_OUTPUT_DIR="results"
CONFIG_JSON_OUTPUT="training_metrics.json"
# end of General Configuration

#
# Model Selection
#
CONFIG_MODEL_MODE_SINGLE=y
# CONFIG_MODEL_MODE_MULTIPLE is not set
# CONFIG_MODEL_SELECT_LENET5 is not set
# CONFIG_MODEL_SELECT_RESNET18 is not set
# CONFIG_MODEL_SELECT_RESNET50 is not set
CONFIG_MODEL_SELECT_GPT2=y
CONFIG_MODEL_GPT2=y
CONFIG_MODEL="gpt2"
CONFIG_TEST_MODELS="gpt2"

#
# GPT-2 Configuration
#
CONFIG_GPT2_MODEL_124M=y
# CONFIG_GPT2_MODEL_350M is not set
# CONFIG_GPT2_MODEL_774M is not set
# CONFIG_GPT2_MODEL_1558M is not set
CONFIG_GPT2_MODEL_NAME="gpt2"
# CONFIG_GPT2_DATASET_SHAKESPEARE is not set
# CONFIG_GPT2_DATASET_FINEWEBEDU is not set
# CONFIG_GPT2_DATASET_OPENWEBTEXT is not set
CONFIG_GPT2_DATASET_TINYSTORIES=y
# CONFIG_GPT2_DATASET_CUSTOM is not set
CONFIG_GPT2_DATASET_NAME="tinystories"
CONFIG_GPT2_BLOCK_SIZE=1024
CONFIG_GPT2_EVAL_INTERVAL=50
CONFIG_GPT2_EVAL_SAMPLES=200
CONFIG_GPT2_WARMUP_STEPS=2000
CONFIG_GPT2_DECAY_LR=y
CONFIG_GPT2_MIN_LR="6e-5"
CONFIG_GPT2_MAX_ITERS=10000
CONFIG_GPT2_MAX_TIME=14400
CONFIG_GPT2_LOG_INTERVAL=10
CONFIG_GPT2_CUDNN_BENCHMARK=y
CONFIG_GPT2_TF32_ALLOWED=y
CONFIG_GPT2_AMP_DTYPE="bfloat16"
CONFIG_GPT2_GENERATION_TEMPERATURE="0.8"
CONFIG_GPT2_GENERATION_TOP_K=200
CONFIG_GPT2_GENERATION_MAX_TOKENS=500
CONFIG_GPT2_FLASH_ATTENTION=y
CONFIG_GPT2_WEIGHT_TYING=y
CONFIG_GPT2_DROPOUT="0.1"
CONFIG_GPT2_BIAS=y
# CONFIG_GPT2_USE_DDP is not set
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER0=y
# CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER1 is not set
# CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER2 is not set
# CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER3 is not set
# CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER4 is not set
# CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER5 is not set
# CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER6 is not set
# CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER7 is not set
# CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER8 is not set
# CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER9 is not set
CONFIG_GPT2_ADAMWPRUNE_DEFAULT_VARIANT="bitter0"
# CONFIG_GPT2_VANILLA_ABLATION_MODE is not set

#
# Mechanistic Interpretability Options
#
# CONFIG_KNLP_MECHINT is not set
# end of Mechanistic Interpretability Options
# end of GPT-2 Configuration
# end of Model Selection

CONFIG_OPTIMIZER_SUPPORTS_MAGNITUDE_PRUNING=y
CONFIG_OPTIMIZER_SUPPORTS_MOVEMENT_PRUNING=y

#
# Optimizer Selection
#
# CONFIG_OPTIMIZER_MODE_NONE is not set
CONFIG_OPTIMIZER_MODE_SINGLE=y
# CONFIG_OPTIMIZER_MODE_MULTIPLE is not set
# CONFIG_OPTIMIZER_SELECT_SGD is not set
# CONFIG_OPTIMIZER_SELECT_ADAM is not set
# CONFIG_OPTIMIZER_SELECT_ADAMW is not set
# CONFIG_OPTIMIZER_SELECT_ADAMWADV is not set
CONFIG_OPTIMIZER_SELECT_ADAMWSPAM=y
# CONFIG_OPTIMIZER_SELECT_ADAMWPRUNE is not set
CONFIG_OPTIMIZER_ENABLED_ADAMWSPAM=y
CONFIG_OPTIMIZER_COUNT=1
CONFIG_OPTIMIZER_DEFAULT="adamwspam"

#
# Advanced Optimizer Configuration
#
CONFIG_ADV_USE_AMSGRAD=y
CONFIG_ADV_WEIGHT_DECAY="0.01"
CONFIG_ADV_USE_COSINE_ANNEALING=y
CONFIG_ADV_COSINE_ETA_MIN="1e-6"
# end of Advanced Optimizer Configuration

#
# SPAM Configuration
#
CONFIG_SPAM_THETA="50.0"
CONFIG_SPAM_ENABLE_CLIP=y
CONFIG_SPAM_SPIKE_THRESHOLD="2.0"
CONFIG_SPAM_PERIODIC_RESET=y
CONFIG_SPAM_INTERVAL=1000
CONFIG_SPAM_WARMUP=y
CONFIG_SPAM_WARMUP_STEPS=1000
# end of SPAM Configuration

# CONFIG_TEST_MATRIX_MODE is not set
CONFIG_OPTIMIZER_ADAMWSPAM=y
CONFIG_OPTIMIZER="adamwspam"
# end of Optimizer Selection

#
# Pruning Configuration
#
CONFIG_PRUNING_MODE_NONE=y
# CONFIG_PRUNING_MODE_SINGLE is not set
# CONFIG_PRUNING_MODE_MULTIPLE is not set
CONFIG_PRUNING_ENABLED_NONE=y
CONFIG_PRUNING_COUNT=0
CONFIG_PRUNING_DEFAULT="none"
CONFIG_PRUNING_NONE=y
CONFIG_PRUNING_METHOD="none"
CONFIG_TEST_PRUNING_METHODS=""
# end of Pruning Configuration

#
# Reciprocal Attention (RA) + MLA (Experimental)
#
# CONFIG_ENABLE_RA_MLA is not set
# end of Reciprocal Attention (RA) + MLA (Experimental)

#
# Advanced Options
#
CONFIG_COMPILE_AUTO=y
# CONFIG_COMPILE_MANUAL is not set
CONFIG_MIXED_PRECISION=y
CONFIG_GPU_WARMUP=y
CONFIG_PIN_MEMORY=y
# CONFIG_GPU_MONITOR is not set
CONFIG_PERSISTENT_WORKERS=y
CONFIG_PREFETCH_FACTOR=4
CONFIG_SAVE_CHECKPOINT=y
CONFIG_CHECKPOINT_INTERVAL=1000
# end of Advanced Options

#
# Experiment Tracking
#

#
# Enable any combination of trackers (they can run simultaneously)
#

#
# CLI: make defconfig TRACKER=wandb,trackio (or both, none, wandb, trackio)
#
CONFIG_TRACKER_SET_BY_CLI=y
CONFIG_TRACKER_CLI_VALUE="wandb,trackio"
CONFIG_ENABLE_TRACKIO=y
CONFIG_ENABLE_WANDB=y
CONFIG_TRACKER_PROJECT="gpt2-kvsplice-ablation-70pct-a100-40g"
CONFIG_TRACKER_RUN_NAME=""
CONFIG_WANDB_PROJECT=""
CONFIG_WANDB_ENTITY=""
# CONFIG_WANDB_OFFLINE is not set
CONFIG_BASELINE_RUN_ID=""
CONFIG_TRACKIO_PORT=7860
# end of Experiment Tracking

CONFIG_INFERENCE_BENCHMARK=y
CONFIG_RUN_LM_EVAL=y
CONFIG_LM_EVAL_TASKS="hellaswag"
CONFIG_LM_EVAL_LIMIT=100

#
# MLA (Multi-head Latent Attention)
#
CONFIG_ENABLE_MLA=y
CONFIG_MLA_VARIANT="mla,mla_kv"
# end of MLA (Multi-head Latent Attention)

#
# Hierarchical Memory Tiering (Experimental)
#
# CONFIG_ENABLE_HIERARCHICAL_TIERING is not set
CONFIG_TIERING_METHOD="none"
# end of Hierarchical Memory Tiering (Experimental)

#
# Test Matrix
#
CONFIG_TEST_RESULTS_DIR=""
CONFIG_AUTO_GENERATE_GRAPHS=y
CONFIG_PARALLEL_JOBS=1
# end of Test Matrix

#
# Debugging
#
# CONFIG_DEBUG is not set
CONFIG_VERBOSE=y
CONFIG_LOG_LEVEL="INFO"
# CONFIG_PROFILE is not set
# CONFIG_DRY_RUN is not set
# CONFIG_INFERENCE_TEST is not set
# end of Debugging
