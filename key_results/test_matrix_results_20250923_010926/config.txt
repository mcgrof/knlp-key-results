#
# Automatically generated file; DO NOT EDIT.
# AdamWPrune v1.0.0 - Neural Network Training Configuration
#

#
# General Configuration
#
CONFIG_BATCH_SIZE=32
CONFIG_NUM_EPOCHS=10
CONFIG_LEARNING_RATE="6e-4"
CONFIG_NUM_WORKERS=16
CONFIG_DEVICE="cuda"
CONFIG_DATA_DIR="data"
CONFIG_OUTPUT_DIR="bitter_lesson_results"
CONFIG_JSON_OUTPUT="training_metrics.json"
# end of General Configuration

#
# Model Selection
#
CONFIG_MODEL_MODE_SINGLE=y
# CONFIG_MODEL_MODE_MULTIPLE is not set
# CONFIG_MODEL_SELECT_LENET5 is not set
# CONFIG_MODEL_SELECT_RESNET18 is not set
# CONFIG_MODEL_SELECT_RESNET50 is not set
CONFIG_MODEL_SELECT_GPT2=y
CONFIG_MODEL_GPT2=y
CONFIG_MODEL="gpt2"
CONFIG_TEST_MODELS="gpt2"

#
# GPT-2 Configuration
#
CONFIG_GPT2_MODEL_124M=y
# CONFIG_GPT2_MODEL_350M is not set
# CONFIG_GPT2_MODEL_774M is not set
# CONFIG_GPT2_MODEL_1558M is not set
CONFIG_GPT2_MODEL_NAME="gpt2"
# CONFIG_GPT2_DATASET_SHAKESPEARE is not set
CONFIG_GPT2_DATASET_FINEWEBEDU=y
# CONFIG_GPT2_DATASET_OPENWEBTEXT is not set
# CONFIG_GPT2_DATASET_CUSTOM is not set
CONFIG_GPT2_DATASET_NAME="finewebedu"
CONFIG_GPT2_BLOCK_SIZE=1024
CONFIG_GPT2_GRADIENT_ACCUMULATION=4
CONFIG_GPT2_EVAL_INTERVAL=500
CONFIG_GPT2_EVAL_SAMPLES=200
CONFIG_GPT2_WARMUP_STEPS=2000
CONFIG_GPT2_DECAY_LR=y
CONFIG_GPT2_MIN_LR="6e-5"
CONFIG_GPT2_GENERATION_TEMPERATURE="0.8"
CONFIG_GPT2_GENERATION_TOP_K=200
CONFIG_GPT2_GENERATION_MAX_TOKENS=500
CONFIG_GPT2_FLASH_ATTENTION=y
CONFIG_GPT2_COMPILE=y
CONFIG_GPT2_WEIGHT_TYING=y
CONFIG_GPT2_DROPOUT="0.1"
CONFIG_GPT2_BIAS=y
# CONFIG_GPT2_USE_DDP is not set
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER0=y
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER1=y
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER2=y
CONFIG_GPT2_ADAMWPRUNE_DEFAULT_VARIANT="bitter0"
# end of GPT-2 Configuration
# end of Model Selection

CONFIG_OPTIMIZER_SUPPORTS_MAGNITUDE_PRUNING=y
CONFIG_OPTIMIZER_SUPPORTS_MOVEMENT_PRUNING=y
CONFIG_OPTIMIZER_SUPPORTS_STATE_PRUNING=y

#
# Optimizer Selection
#
# CONFIG_OPTIMIZER_MODE_NONE is not set
# CONFIG_OPTIMIZER_MODE_SINGLE is not set
CONFIG_OPTIMIZER_MODE_MULTIPLE=y

#
# Select optimizers to enable
#
# CONFIG_OPTIMIZER_ENABLE_SGD is not set
# CONFIG_OPTIMIZER_ENABLE_ADAM is not set
# CONFIG_OPTIMIZER_ENABLE_ADAMW is not set
# CONFIG_OPTIMIZER_ENABLE_ADAMWADV is not set
CONFIG_OPTIMIZER_ENABLE_ADAMWSPAM=y
CONFIG_OPTIMIZER_ENABLE_ADAMWPRUNE=y
CONFIG_OPTIMIZER_ENABLED_ADAMWSPAM=y
CONFIG_OPTIMIZER_ENABLED_ADAMWPRUNE=y
CONFIG_OPTIMIZER_DEFAULT=""

#
# Advanced Optimizer Configuration
#
CONFIG_ADV_USE_AMSGRAD=y
CONFIG_ADV_WEIGHT_DECAY="0.01"
CONFIG_ADV_USE_COSINE_ANNEALING=y
CONFIG_ADV_COSINE_ETA_MIN="1e-6"
# end of Advanced Optimizer Configuration

#
# SPAM Configuration
#
CONFIG_SPAM_THETA="50.0"
CONFIG_SPAM_ENABLE_CLIP=y
CONFIG_SPAM_SPIKE_THRESHOLD="2.0"
CONFIG_SPAM_PERIODIC_RESET=y
CONFIG_SPAM_INTERVAL=1000
CONFIG_SPAM_WARMUP=y
CONFIG_SPAM_WARMUP_STEPS=1000
# end of SPAM Configuration

# CONFIG_ADAMWPRUNE_BASE_ADAM is not set
# CONFIG_ADAMWPRUNE_BASE_ADAMW is not set
# CONFIG_ADAMWPRUNE_BASE_ADAMWADV is not set
CONFIG_ADAMWPRUNE_BASE_ADAMWSPAM=y
CONFIG_ADAMWPRUNE_BASE_OPTIMIZER_NAME="adamwspam"

#
# AdamWPrune Configuration
#
CONFIG_ADAMWPRUNE_ENABLE_PRUNING=y
CONFIG_ADAMWPRUNE_PRUNING_METHOD="state"
CONFIG_ADAMWPRUNE_TARGET_SPARSITY="0.5"
CONFIG_ADAMWPRUNE_WARMUP_STEPS=100
CONFIG_ADAMWPRUNE_FREQUENCY=50
CONFIG_ADAMWPRUNE_RAMP_END_EPOCH=75
CONFIG_ADAMWPRUNE_BETA1="0.9"
CONFIG_ADAMWPRUNE_BETA2="0.95"
CONFIG_ADAMWPRUNE_WEIGHT_DECAY="0.1"
CONFIG_ADAMWPRUNE_AMSGRAD=y
# end of AdamWPrune Configuration

CONFIG_TEST_MATRIX_MODE=y
CONFIG_TEST_OPTIMIZER_ENABLED_ADAMWSPAM=y
CONFIG_TEST_OPTIMIZER_ENABLED_ADAMWPRUNE=y
CONFIG_OPTIMIZER=""
# end of Optimizer Selection

#
# Pruning Configuration
#
# CONFIG_PRUNING_MODE_NONE is not set
# CONFIG_PRUNING_MODE_SINGLE is not set
CONFIG_PRUNING_MODE_MULTIPLE=y

#
# Select pruning methods to enable
#
# CONFIG_PRUNING_ENABLE_NONE is not set
CONFIG_PRUNING_ENABLE_MAGNITUDE=y
# CONFIG_PRUNING_ENABLE_MOVEMENT is not set
CONFIG_PRUNING_ENABLE_STATE=y
CONFIG_PRUNING_ENABLED_MAGNITUDE=y
CONFIG_PRUNING_ENABLED_STATE=y
CONFIG_PRUNING_DEFAULT=""

#
# Select sparsity levels to test
#
CONFIG_SPARSITY_ENABLE_50=y
# CONFIG_SPARSITY_ENABLE_70 is not set
# CONFIG_SPARSITY_ENABLE_90 is not set
# CONFIG_SPARSITY_ENABLE_95 is not set
# CONFIG_SPARSITY_ENABLE_99 is not set

#
# Pruning Parameters
#
CONFIG_PRUNING_WARMUP=100
CONFIG_PRUNING_FREQUENCY=50
CONFIG_PRUNING_RAMP_END_EPOCH=8
# end of Pruning Parameters

#
# Magnitude Pruning Configuration
#
CONFIG_MAGNITUDE_PRUNING_NORM="l1"
# CONFIG_MAGNITUDE_PRUNING_STRUCTURED is not set
# end of Magnitude Pruning Configuration

#
# State Pruning Configuration
#
CONFIG_STATE_PRUNING_STRATEGY="hybrid"
CONFIG_STATE_PRUNING_MOMENTUM_WEIGHT="0.5"
# end of State Pruning Configuration

#
# Pruning Analysis
#
# CONFIG_PRUNING_SAVE_MASKS is not set
# CONFIG_PRUNING_VISUALIZE_MASKS is not set
CONFIG_PRUNING_LOG_SPARSITY=y
# end of Pruning Analysis

CONFIG_PRUNING_METHOD="none"
CONFIG_TEST_PRUNING_MAGNITUDE=y
CONFIG_TEST_PRUNING_METHODS=""
CONFIG_TEST_SPARSITY_50=y
# end of Pruning Configuration

#
# Advanced Options
#
CONFIG_COMPILE_MODEL=y
CONFIG_MIXED_PRECISION=y
CONFIG_GPU_WARMUP=y
CONFIG_PIN_MEMORY=y
# CONFIG_GPU_MONITOR is not set
CONFIG_PERSISTENT_WORKERS=y
CONFIG_PREFETCH_FACTOR=2
CONFIG_SAVE_CHECKPOINT=y
CONFIG_CHECKPOINT_INTERVAL=100
# end of Advanced Options

#
# Experiment Tracking
#

#
# Enable any combination of trackers (they can run simultaneously)
#

#
# CLI: make defconfig TRACKER=wandb,trackio (or both, none, wandb, trackio)
#
CONFIG_TRACKER_SET_BY_CLI=y
CONFIG_TRACKER_CLI_VALUE="wandb,trackio"
CONFIG_ENABLE_TRACKIO=y
CONFIG_ENABLE_WANDB=y
CONFIG_TRACKER_PROJECT="tracking-e97b5"
CONFIG_TRACKER_RUN_NAME=""
CONFIG_WANDB_PROJECT=""
CONFIG_WANDB_ENTITY=""
# CONFIG_WANDB_OFFLINE is not set
CONFIG_TRACKIO_PORT=7860
# end of Experiment Tracking

#
# Test Matrix
#
CONFIG_TEST_RESULTS_DIR=""
CONFIG_AUTO_GENERATE_GRAPHS=y
CONFIG_PARALLEL_JOBS=1
# end of Test Matrix

#
# Debugging
#
# CONFIG_DEBUG is not set
CONFIG_VERBOSE=y
CONFIG_LOG_LEVEL="INFO"
# CONFIG_PROFILE is not set
# CONFIG_INFERENCE_TEST is not set
# end of Debugging
